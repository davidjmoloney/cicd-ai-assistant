# github/pr_generator.py
"""
Minimal PR Generator for CI/CD AI Assistant.

Creates pull requests from FixPlan objects generated by agent_handler.

Configuration via environment variables (use .env file locally):
    GITHUB_TOKEN              - GitHub PAT with repo permissions
    TARGET_REPO_OWNER         - Owner of target repository (e.g., "my-org")
    TARGET_REPO_NAME          - Name of target repository (e.g., "backend")
    TARGET_REPO_DEFAULT_BRANCH - Branch to create PRs against (default: "main")
    PR_BRANCH_PREFIX          - Prefix for branch names (default: "ai-fix")
    PR_LABELS                 - Comma-separated labels (default: "ai-generated")
    PR_DRAFT_MODE             - Create as draft PR (default: "false")
"""
from __future__ import annotations

import base64
import hashlib
import os
import time
import logging

from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

import httpx
from dotenv import load_dotenv

from agents.agent_handler import CodeEdit, EditType, FileEdit, FixPlan


# Load environment variables
load_dotenv()

# ============================================================================
# Configuration (self-explanatory environment variable names)
# ============================================================================
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", "").strip()
TARGET_REPO_OWNER = os.getenv("TARGET_REPO_OWNER", "").strip()
TARGET_REPO_NAME = os.getenv("TARGET_REPO_NAME", "").strip()
TARGET_REPO_DEFAULT_BRANCH = os.getenv("TARGET_REPO_DEFAULT_BRANCH", "david/cicd-ai-assistant").strip()
PR_BRANCH_PREFIX = os.getenv("PR_BRANCH_PREFIX", "cicd-agent-fix").strip()
PR_LABELS = [l.strip() for l in os.getenv("PR_LABELS", "cicd-agent-generated").split(",") if l.strip()]
PR_DRAFT_MODE = os.getenv("PR_DRAFT_MODE", "false").lower() in ("true", "1", "yes")

# API constants
GITHUB_API_URL = "https://api.github.com"
MAX_RETRIES = 4
RETRY_DELAYS = [2, 4, 8, 16]

# Logging Mode Environment Settings
DEBUG_MODE_ON = os.getenv("DEBUG_MODE_ON", "false").lower() in ("true", "1", "yes")


# ============================================================================
# Result Type
# ============================================================================

@dataclass
class PRResult:
    """Result of PR creation."""
    success: bool
    pr_url: Optional[str] = None
    pr_number: Optional[int] = None
    branch_name: Optional[str] = None
    error: Optional[str] = None
    files_changed: list[str] = field(default_factory=list)


# ============================================================================
# Edit Application
# ============================================================================

def apply_edits_to_content(content: str, edits: list[CodeEdit]) -> str:
    """
    Apply CodeEdit operations to file content.

    Edits are applied bottom-to-top to preserve line numbers.
    """
    if not edits:
        return content

    lines = content.split("\n")

    # Sort edits by position descending (apply bottom-to-top)
    sorted_edits = sorted(
        edits,
        key=lambda e: (e.span.start.row, e.span.start.column),
        reverse=True,
    )

    for edit in sorted_edits:
        lines = _apply_edit(lines, edit)

    return "\n".join(lines)


def _apply_edit(lines: list[str], edit: CodeEdit) -> list[str]:
    """Apply a single edit to lines."""
    # Convert to 0-based index
    start_row = max(0, edit.span.start.row - 1)
    end_row = max(0, edit.span.end.row - 1)
    start_col = max(0, edit.span.start.column - 1)
    end_col = max(0, edit.span.end.column -1)

    if not lines:
        if edit.edit_type in (EditType.INSERT, EditType.REPLACE):
            return edit.content.split("\n")
        return lines

    start_row = min(start_row, len(lines) - 1)
    end_row = min(end_row, len(lines) - 1)

    if edit.edit_type == EditType.DELETE:
        if start_row == end_row:
            line = lines[start_row]
            lines[start_row] = line[:start_col] + line[end_col:]
        else:
            prefix = lines[start_row][:start_col]
            suffix = lines[end_row][end_col:]
            lines[start_row] = prefix + suffix
            del lines[start_row + 1:end_row + 1]

    elif edit.edit_type == EditType.INSERT:
        line = lines[start_row]
        new_content = line[:start_col] + edit.content + line[start_col:]
        lines[start_row:start_row + 1] = new_content.split("\n")

    elif edit.edit_type == EditType.REPLACE:
        prefix = lines[start_row][:start_col]
        suffix = lines[end_row][end_col:]
        new_content = prefix + edit.content + suffix
        lines[start_row:end_row + 1] = new_content.split("\n")

    return lines


# ============================================================================
# GitHub API Helpers
# ============================================================================

def _github_headers() -> dict[str, str]:
    """Get headers for GitHub API requests."""
    return {
        "Accept": "application/vnd.github+json",
        "Authorization": f"Bearer {GITHUB_TOKEN}",
        "X-GitHub-Api-Version": "2022-11-28",
    }


def _github_request(
    client: httpx.Client,
    method: str,
    path: str,
    json_data: Optional[dict] = None,
) -> dict[str, Any]:
    """Make a GitHub API request with retry logic."""
    url = f"{GITHUB_API_URL}{path}"

    for attempt in range(MAX_RETRIES + 1):
        try:
            response = client.request(method, url, json=json_data)

            if response.status_code in (200, 201):
                return response.json()
            elif response.status_code == 422:
                error = response.json()
                raise GitHubError(f"Validation error: {error.get('message', 'Unknown')}")
            elif response.status_code >= 500 and attempt < MAX_RETRIES:
                time.sleep(RETRY_DELAYS[attempt])
                continue
            else:
                error = response.json() if response.content else {}
                raise GitHubError(f"API error {response.status_code}: {error.get('message', 'Unknown')}")

        except httpx.RequestError as e:
            if attempt < MAX_RETRIES:
                time.sleep(RETRY_DELAYS[attempt])
                continue
            raise GitHubError(f"Network error: {e}")

    raise GitHubError("Max retries exceeded")


class GitHubError(Exception):
    """GitHub API error."""
    pass


# ============================================================================
# PR Generator
# ============================================================================

class PRGenerator:
    """
    Creates pull requests from FixPlan objects.

    Usage:
        generator = PRGenerator()
        result = generator.create_pr(fix_plan)

        if result.success:
            print(f"PR created: {result.pr_url}")
    """

    def __init__(self) -> None:
        """Initialize PR generator with config from environment."""
        if not GITHUB_TOKEN:
            raise ValueError("GITHUB_TOKEN environment variable not set")
        if not TARGET_REPO_OWNER or not TARGET_REPO_NAME:
            raise ValueError("TARGET_REPO_OWNER and TARGET_REPO_NAME must be set")

    def create_pr(self, fix_plan: FixPlan, base_branch: Optional[str] = None) -> PRResult:
        """
        Create a PR from a FixPlan.

        Args:
            fix_plan: FixPlan from agent_handler containing file edits
            base_branch: Branch to create PR against (uses default if None)

        Returns:
            PRResult with PR URL and details, or error information
        """
        if not fix_plan.file_edits:
            return PRResult(success=False, error="No file edits in fix plan")

        base = base_branch or TARGET_REPO_DEFAULT_BRANCH
        owner = TARGET_REPO_OWNER
        repo = TARGET_REPO_NAME

        try:
            with httpx.Client(headers=_github_headers(), timeout=30.0) as client:
                # 1. Get base branch SHA
                ref_data = _github_request(client, "GET", f"/repos/{owner}/{repo}/git/ref/heads/{base}")
                base_sha = ref_data["object"]["sha"]

                # 2. Create new branch
                branch_name = self._generate_branch_name(fix_plan)
                _github_request(client, "POST", f"/repos/{owner}/{repo}/git/refs", {
                    "ref": f"refs/heads/{branch_name}",
                    "sha": base_sha,
                })

                # 3. Group edits by file (to handle multiple FileEdits for same file)
                merged_file_edits = self._merge_file_edits(fix_plan.file_edits)

                # 4. Apply edits and commit each unique file
                files_changed: list[str] = []
                for file_edit in merged_file_edits:
                    if self._commit_file_edit(client, owner, repo, file_edit, branch_name, base):
                        files_changed.append(file_edit.file_path)

                if not files_changed:
                    return PRResult(success=False, error="No files were modified", branch_name=branch_name)

                # 5. Create pull request
                title = self._generate_title(fix_plan)
                body = self._generate_body(fix_plan, files_changed)

                pr_data = _github_request(client, "POST", f"/repos/{owner}/{repo}/pulls", {
                    "title": title,
                    "body": body,
                    "head": branch_name,
                    "base": base,
                    "draft": PR_DRAFT_MODE,
                })

                pr_number = pr_data.get("number")
                pr_url = pr_data.get("html_url")

                # 6. Add labels
                if pr_number and PR_LABELS:
                    labels = list(PR_LABELS)
                    if fix_plan.group_signal_type:
                        labels.append(fix_plan.group_signal_type)
                    try:
                        _github_request(client, "POST", f"/repos/{owner}/{repo}/issues/{pr_number}/labels", {
                            "labels": labels
                        })
                    except GitHubError:
                        pass  # Labels are non-critical

                return PRResult(
                    success=True,
                    pr_url=pr_url,
                    pr_number=pr_number,
                    branch_name=branch_name,
                    files_changed=files_changed,
                )

        except GitHubError as e:
            return PRResult(success=False, error=str(e))
        except Exception as e:
            return PRResult(success=False, error=f"Unexpected error: {e}")

    def _commit_file_edit(
        self,
        client: httpx.Client,
        owner: str,
        repo: str,
        file_edit: FileEdit,
        branch: str,
        base_branch: str,
    ) -> bool:
        """Apply a FileEdit and commit it. Returns True if successful."""
        try:
            # Get current file content from the branch being built (to chain commits)
            file_data = _github_request(
                client, "GET",
                f"/repos/{owner}/{repo}/contents/{file_edit.file_path}?ref={branch}"
            )
            original_content = base64.b64decode(file_data["content"]).decode("utf-8")
            file_sha = file_data["sha"]

            with (Path("/home/devel/cicd-ai-assistant/scripts/debug/original_content.txt")).open("w", encoding="utf-8") as f:
                    f.write(original_content)

            # Apply edits
            new_content = apply_edits_to_content(original_content, file_edit.edits)

            with (Path("/home/devel/cicd-ai-assistant/scripts/debug/new_content.txt")).open("w", encoding="utf-8") as f:
                    f.write(new_content)

            if new_content == original_content:
                return False  # No changes

            # Log the details before committing
            if DEBUG_MODE_ON: 
                logging.info(f"Attempting to commit {file_edit.file_path}")
                logging.info(f"  Branch: {branch}")
                logging.info(f"  File SHA: {file_sha}")
                logging.info(f"  Original length: {len(original_content)} bytes")
                logging.info(f"  New length: {len(new_content)} bytes")
                logging.info(f"  Content changed: {original_content != new_content}")

            # Commit updated file
            commit_msg = self._generate_commit_message(file_edit)

            encoded_content = base64.b64encode(new_content.encode("utf-8")).decode("utf-8")

            try:
                _github_request(client, "PUT", f"/repos/{owner}/{repo}/contents/{file_edit.file_path}", {
                    "message": commit_msg,
                    "content": encoded_content,
                    "sha": file_sha,
                    "branch": branch,
                })
                logging.info(f"✓ Successfully committed {file_edit.file_path}")
                return True
            except GitHubError as e:
                logging.error(f"✗ Failed to commit {file_edit.file_path}: {e}")
                # Re-raise to preserve original behavior
                raise

        except GitHubError:
            return False

    def _merge_file_edits(self, file_edits: list[FileEdit]) -> list[FileEdit]:
        """
        Merge multiple FileEdit objects for the same file into a single FileEdit.

        This prevents line number conflicts when multiple edits target the same file.
        All edits for a file are combined and will be applied in a single commit.
        """
        from collections import defaultdict

        # Group edits by file path
        edits_by_file: dict[str, list[FileEdit]] = defaultdict(list)
        for file_edit in file_edits:
            edits_by_file[file_edit.file_path].append(file_edit)

        # Merge edits for each file
        merged: list[FileEdit] = []
        for file_path, edits_list in edits_by_file.items():
            if len(edits_list) == 1:
                # Only one FileEdit for this file, use as-is
                merged.append(edits_list[0])
            else:
                # Multiple FileEdits for same file - merge them
                all_edits: list[CodeEdit] = []
                reasonings: list[str] = []

                for file_edit in edits_list:
                    all_edits.extend(file_edit.edits)
                    if file_edit.reasoning:
                        reasonings.append(file_edit.reasoning)

                merged.append(FileEdit(
                    file_path=file_path,
                    edits=all_edits,
                    reasoning=" | ".join(reasonings) if reasonings else ""
                ))

        return merged

    def _generate_commit_message(self, file_edit: FileEdit) -> str:
        """
        Generate commit message that includes all edit descriptions.

        For merged FileEdits with multiple fixes, lists each one.
        """
        if not file_edit.edits:
            return "fix: apply automated fixes"

        if len(file_edit.edits) == 1:
            return f"fix: {file_edit.edits[0].description}"

        # Multiple edits - create a structured commit message
        title = f"fix: {len(file_edit.edits)} fixes in {file_edit.file_path}"
        details = []
        for edit in file_edit.edits:
            details.append(f"- Line {edit.span.start.row}: {edit.description}")

        return f"{title}\n{chr(10).join(details)}"

    def _generate_branch_name(self, fix_plan: FixPlan) -> str:
        """Generate unique branch name."""
        signal_type = fix_plan.group_signal_type or "fix"
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S")
        short_hash = hashlib.sha256(f"{fix_plan.group_tool_id}{timestamp}".encode()).hexdigest()[:6]
        return f"{PR_BRANCH_PREFIX}/{signal_type}/{timestamp}-{short_hash}"

    def _generate_title(self, fix_plan: FixPlan) -> str:
        """Generate PR title."""
        num_files = len(fix_plan.file_edits)
        total_edits = sum(len(fe.edits) for fe in fix_plan.file_edits)
        signal_type = fix_plan.group_signal_type or "code"

        if num_files == 1:
            return f"Fix {total_edits} {signal_type} issue(s) in {fix_plan.file_edits[0].file_path}"
        return f"Fix {total_edits} {signal_type} issue(s) across {num_files} files"

    def _generate_body(self, fix_plan: FixPlan, files_changed: list[str]) -> str:
        """Generate PR body."""
        lines = [
            "## Summary",
            fix_plan.summary or f"Automated fixes for {fix_plan.group_signal_type or 'code'} issues.",
            "",
            f"**Confidence:** {int(fix_plan.confidence * 100)}%",
            "",
            "## Files Changed",
        ]

        for f in files_changed:
            lines.append(f"- `{f}`")

        lines.extend(["", "## Changes"])

        for fe in fix_plan.file_edits:
            if fe.file_path in files_changed:
                lines.append(f"### `{fe.file_path}`")
                if fe.reasoning:
                    lines.append(f"**Reasoning:** {fe.reasoning}")
                for edit in fe.edits:
                    lines.append(f"- **{edit.edit_type.value}** (line {edit.span.start.row}): {edit.description}")
                lines.append("")

        if fix_plan.warnings:
            lines.extend(["## Warnings"])
            for w in fix_plan.warnings:
                lines.append(f"- ⚠️ {w}")

        lines.extend([
            "",
            "---",
            "*Generated by CI/CD AI Assistant*",
        ])

        return "\n".join(lines)

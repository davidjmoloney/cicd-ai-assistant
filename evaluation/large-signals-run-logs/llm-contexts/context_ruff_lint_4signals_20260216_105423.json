{
  "_debug_metadata": {
    "timestamp": "20260216_105423",
    "tool_id": "ruff",
    "signal_type": "lint",
    "num_signals": 4,
    "signal_files": [
      "ria/services/search_service.py"
    ],
    "system_prompt_length": 8600,
    "user_prompt_length": 13558
  },
  "context": {
    "group": {
      "tool_id": "ruff",
      "signal_type": "lint",
      "group_size": 4
    },
    "signals": [
      {
        "signal": {
          "tool_id": "ruff",
          "signal_type": "lint",
          "severity": "low",
          "rule_code": "F541",
          "message": "f-string without any placeholders",
          "docs_url": "https://docs.astral.sh/ruff/rules/f-string-missing-placeholders",
          "file_path": "ria/services/search_service.py",
          "span": {
            "start": {
              "row": 52,
              "column": 21
            },
            "end": {
              "row": 52,
              "column": 77
            }
          }
        },
        "file_read_error": null,
        "code_context": {
          "window": {
            "file_path": "ria/services/search_service.py",
            "start_row": 22,
            "end_row": 82,
            "text": "\nlogger = get_logger(__name__)\n\n\ndef canonicalize_domain(value: Optional[str]) -> Optional[str]:\n    \"\"\"Canonicalize a domain value by extracting the netloc.\"\"\"\n    if not value:\n        return None\n    v = value.strip().lower()\n    if not v:\n        return None\n    if not v.startswith(\"http\"):\n        v_for_parse = \"http://\" + v\n    else:\n        v_for_parse = v\n    try:\n        netloc = urlparse(v_for_parse).netloc\n        if netloc.startswith(\"www.\"):\n            netloc = netloc[4:]\n        return netloc\n    except Exception:\n        return v\n\n\ndef ensure_columns(df: pl.DataFrame, required: List[str]) -> None:\n    \"\"\"Check for required columns and log warnings for missing ones instead of raising errors.\"\"\"\n    missing = [col for col in required if col not in df.columns]\n    if missing:\n        logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n        logger.info(f\"Available columns: {len(df.columns)} total\")\n        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n\ndef attach_domain_column(df: pl.DataFrame, column: str) -> pl.DataFrame:\n    \"\"\"Attach domain column if available, otherwise add empty domain column.\"\"\"\n    if column not in df.columns:\n        logger.warning(f\"\u26a0\ufe0f Website column '{column}' not found, adding empty domain column\")\n        return df.with_columns(pl.lit(None).alias(\"__domain\"))\n    \n    return df.with_columns(\n        pl.col(column)\n        .map_elements(canonicalize_domain, return_dtype=pl.Utf8)\n        .alias(\"__domain\")\n    )\n\n\ndef to_serializable_records(df: pl.DataFrame, limit: int) -> List[Dict[str, Any]]:\n    \"\"\"Convert DataFrame to list of dictionaries, limited to specified count.\"\"\"\n    if df.height == 0:\n        return []\n    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n"
          },
          "imports": {
            "file_path": "ria/services/search_service.py",
            "start_row": 1,
            "end_row": 14,
            "text": "\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n"
          },
          "enclosing_function": {
            "file_path": "ria/services/search_service.py",
            "start_row": 44,
            "end_row": 56,
            "text": "\n\ndef ensure_columns(df: pl.DataFrame, required: List[str]) -> None:\n    \"\"\"Check for required columns and log warnings for missing ones instead of raising errors.\"\"\"\n    missing = [col for col in required if col not in df.columns]\n    if missing:\n        logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n        logger.info(f\"Available columns: {len(df.columns)} total\")\n        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n\n"
          },
          "try_except_block": null,
          "class_definition": null,
          "type_aliases": null,
          "related_function": null,
          "module_constants": null
        },
        "edit_snippet": {
          "file_path": "ria/services/search_service.py",
          "start_row": 50,
          "end_row": 54,
          "text": "    logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n    logger.info(f\"Available columns: {len(df.columns)} total\")\n    logger.info(f\"Missing columns will be handled gracefully in filters\")\nelse:\n    logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n",
          "original_text": "        logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n        logger.info(f\"Available columns: {len(df.columns)} total\")\n        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n",
          "error_line": 52,
          "error_line_in_snippet": 3,
          "snippet_length": 5,
          "base_indent": "    "
        },
        "edit_window_type": "lines",
        "fix_context": {
          "exists": true,
          "applicability": "safe",
          "tool_message": "Remove extraneous `f` prefix",
          "edits": [
            {
              "span": {
                "start": {
                  "row": 52,
                  "column": 21
                },
                "end": {
                  "row": 52,
                  "column": 77
                }
              },
              "content": "\"Missing columns will be handled gracefully in filters\""
            }
          ]
        }
      },
      {
        "signal": {
          "tool_id": "ruff",
          "signal_type": "lint",
          "severity": "low",
          "rule_code": "B007",
          "message": "Loop control variable `field_name` not used within loop body",
          "docs_url": "https://docs.astral.sh/ruff/rules/unused-loop-control-variable",
          "file_path": "ria/services/search_service.py",
          "span": {
            "start": {
              "row": 82,
              "column": 9
            },
            "end": {
              "row": 82,
              "column": 19
            }
          }
        },
        "file_read_error": null,
        "code_context": {
          "window": {
            "file_path": "ria/services/search_service.py",
            "start_row": 52,
            "end_row": 112,
            "text": "        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n\ndef attach_domain_column(df: pl.DataFrame, column: str) -> pl.DataFrame:\n    \"\"\"Attach domain column if available, otherwise add empty domain column.\"\"\"\n    if column not in df.columns:\n        logger.warning(f\"\u26a0\ufe0f Website column '{column}' not found, adding empty domain column\")\n        return df.with_columns(pl.lit(None).alias(\"__domain\"))\n    \n    return df.with_columns(\n        pl.col(column)\n        .map_elements(canonicalize_domain, return_dtype=pl.Utf8)\n        .alias(\"__domain\")\n    )\n\n\ndef to_serializable_records(df: pl.DataFrame, limit: int) -> List[Dict[str, Any]]:\n    \"\"\"Convert DataFrame to list of dictionaries, limited to specified count.\"\"\"\n    if df.height == 0:\n        return []\n    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n"
          },
          "imports": {
            "file_path": "ria/services/search_service.py",
            "start_row": 1,
            "end_row": 14,
            "text": "\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n"
          },
          "enclosing_function": {
            "file_path": "ria/services/search_service.py",
            "start_row": 76,
            "end_row": 99,
            "text": "\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\n"
          },
          "try_except_block": null,
          "class_definition": null,
          "type_aliases": null,
          "related_function": null,
          "module_constants": null
        },
        "edit_snippet": {
          "file_path": "ria/services/search_service.py",
          "start_row": 80,
          "end_row": 84,
          "text": "fund_counts = []\n    \nfor field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n    if column_name in company_record and company_record[column_name] is not None:\n        try:\n",
          "original_text": "    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n",
          "error_line": 82,
          "error_line_in_snippet": 3,
          "snippet_length": 5,
          "base_indent": "    "
        },
        "edit_window_type": "lines",
        "fix_context": {
          "exists": true,
          "applicability": "unsafe",
          "tool_message": "Rename unused `field_name` to `_field_name`",
          "edits": [
            {
              "span": {
                "start": {
                  "row": 82,
                  "column": 9
                },
                "end": {
                  "row": 82,
                  "column": 19
                }
              },
              "content": "_field_name"
            }
          ]
        }
      },
      {
        "signal": {
          "tool_id": "ruff",
          "signal_type": "lint",
          "severity": "low",
          "rule_code": "UP006",
          "message": "Use `dict` instead of `Dict` for type annotation",
          "docs_url": "https://docs.astral.sh/ruff/rules/non-pep585-annotation",
          "file_path": "ria/services/search_service.py",
          "span": {
            "start": {
              "row": 100,
              "column": 67
            },
            "end": {
              "row": 100,
              "column": 71
            }
          }
        },
        "file_read_error": null,
        "code_context": {
          "window": {
            "file_path": "ria/services/search_service.py",
            "start_row": 70,
            "end_row": 130,
            "text": "def to_serializable_records(df: pl.DataFrame, limit: int) -> List[Dict[str, Any]]:\n    \"\"\"Convert DataFrame to list of dictionaries, limited to specified count.\"\"\"\n    if df.height == 0:\n        return []\n    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by percentage (highest first) and return top 3\n    allocations.sort(key=lambda x: x[\"percentage\"], reverse=True)\n    return allocations[:3]\n\n\ndef get_total_clients(company_record: Dict[str, Any]) -> int:\n    \"\"\"Get total count of all clients for a company by summing all client type columns.\"\"\"\n    total_count = 0\n    \n    for column_name in ALL_CLIENT_TYPE_COLUMNS:\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n"
          },
          "imports": {
            "file_path": "ria/services/search_service.py",
            "start_row": 1,
            "end_row": 14,
            "text": "\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n"
          },
          "enclosing_function": {
            "file_path": "ria/services/search_service.py",
            "start_row": 98,
            "end_row": 121,
            "text": "\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by percentage (highest first) and return top 3\n    allocations.sort(key=lambda x: x[\"percentage\"], reverse=True)\n    return allocations[:3]\n\n\n"
          },
          "try_except_block": null,
          "class_definition": null,
          "type_aliases": null,
          "related_function": null,
          "module_constants": null
        },
        "edit_snippet": {
          "file_path": "ria/services/search_service.py",
          "start_row": 98,
          "end_row": 102,
          "text": "\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n",
          "original_text": "\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n",
          "error_line": 100,
          "error_line_in_snippet": 3,
          "snippet_length": 5,
          "base_indent": ""
        },
        "edit_window_type": "lines",
        "fix_context": {
          "exists": true,
          "applicability": "safe",
          "tool_message": "Replace with `dict`",
          "edits": [
            {
              "span": {
                "start": {
                  "row": 100,
                  "column": 67
                },
                "end": {
                  "row": 100,
                  "column": 71
                }
              },
              "content": "dict"
            }
          ]
        }
      },
      {
        "signal": {
          "tool_id": "ruff",
          "signal_type": "lint",
          "severity": "low",
          "rule_code": "B007",
          "message": "Loop control variable `field_name` not used within loop body",
          "docs_url": "https://docs.astral.sh/ruff/rules/unused-loop-control-variable",
          "file_path": "ria/services/search_service.py",
          "span": {
            "start": {
              "row": 104,
              "column": 9
            },
            "end": {
              "row": 104,
              "column": 19
            }
          }
        },
        "file_read_error": null,
        "code_context": {
          "window": {
            "file_path": "ria/services/search_service.py",
            "start_row": 74,
            "end_row": 134,
            "text": "    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by percentage (highest first) and return top 3\n    allocations.sort(key=lambda x: x[\"percentage\"], reverse=True)\n    return allocations[:3]\n\n\ndef get_total_clients(company_record: Dict[str, Any]) -> int:\n    \"\"\"Get total count of all clients for a company by summing all client type columns.\"\"\"\n    total_count = 0\n    \n    for column_name in ALL_CLIENT_TYPE_COLUMNS:\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    total_count += count\n            except (ValueError, TypeError):\n                continue\n    \n"
          },
          "imports": {
            "file_path": "ria/services/search_service.py",
            "start_row": 1,
            "end_row": 14,
            "text": "\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n"
          },
          "enclosing_function": {
            "file_path": "ria/services/search_service.py",
            "start_row": 98,
            "end_row": 121,
            "text": "\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by percentage (highest first) and return top 3\n    allocations.sort(key=lambda x: x[\"percentage\"], reverse=True)\n    return allocations[:3]\n\n\n"
          },
          "try_except_block": null,
          "class_definition": null,
          "type_aliases": null,
          "related_function": null,
          "module_constants": null
        },
        "edit_snippet": {
          "file_path": "ria/services/search_service.py",
          "start_row": 102,
          "end_row": 106,
          "text": "allocations = []\n    \nfor field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n    if column_name in company_record and company_record[column_name] is not None:\n        try:\n",
          "original_text": "    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n",
          "error_line": 104,
          "error_line_in_snippet": 3,
          "snippet_length": 5,
          "base_indent": "    "
        },
        "edit_window_type": "lines",
        "fix_context": {
          "exists": true,
          "applicability": "unsafe",
          "tool_message": "Rename unused `field_name` to `_field_name`",
          "edits": [
            {
              "span": {
                "start": {
                  "row": 104,
                  "column": 9
                },
                "end": {
                  "row": 104,
                  "column": 19
                }
              },
              "content": "_field_name"
            }
          ]
        }
      }
    ],
    "merged_snippet_groups": [
      {
        "signal_indices": [
          2,
          3
        ],
        "edit_snippet": {
          "file_path": "ria/services/search_service.py",
          "start_row": 98,
          "end_row": 106,
          "text": "\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n",
          "original_text": "\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n",
          "error_line": 100,
          "error_line_in_snippet": 3,
          "snippet_length": 9,
          "base_indent": ""
        }
      }
    ],
    "standalone_signal_indices": [
      0,
      1
    ]
  },
  "prompts": {
    "system_prompt": "You are an expert code repair agent. Your task is to make MINIMAL, SURGICAL fixes to code errors.\n\n## CRITICAL PRINCIPLE: MINIMAL CHANGES ONLY\n\nYour job is to fix ONLY the specific error mentioned. You are NOT improving, refactoring, or cleaning up code.\n\n**THE GOLDEN RULE**: Every line in your output that is NOT directly part of the fix MUST be IDENTICAL to the input - same content, same whitespace, same everything.\n\n## How This Works\n\nFor each error signal, you will receive:\n\n1. **Error Information**: Type, message, severity, and rule code\n2. **Edit Snippet**: A small code snippet (~13 lines) containing the error\n   - This is what you need to FIX and RETURN\n   - The error location within the snippet is indicated (e.g., \"Error on line 4 of 13\")\n3. **Context Window**: A larger code window (~30 lines) around the error for understanding\n   - Use this to understand the surrounding code, but DON'T return it\n\n4. **Tailored Context** (varies by signal type - optimized to reduce token usage):\n   - **Imports**: The file's import block (for type definitions, dependencies)\n     - Included for: type errors, undefined names, most issues\n     - Excluded for: import-only errors, bare except blocks\n   - **Enclosing Function**: The function containing the error (for understanding scope/logic)\n     - Included for: type errors, docstring errors, function-level issues\n     - Excluded for: import errors (global scope), bare except (sent separately)\n   - **Try/Except Block**: The try/except block containing the error\n     - Included for: bare except errors (E722)\n     - Excluded for: most other errors\n\nNote: Context is carefully selected to provide what you need while minimizing token usage.\nNot all context is present for every error - you'll only receive relevant context.\n\n## Response Format\n\nFor EACH signal/snippet you receive, respond with this EXACT format:\n\n```\n===== FIX FOR: <file_path> =====\nCONFIDENCE: <0.0-1.0>\nREASONING: <brief explanation of the fix>\n\n```FIXED_CODE\n<complete fixed snippet - ALL lines from edit_snippet, with ONLY the fix applied>\n```\n\nWARNINGS: <any caveats, or \"None\">\n===== END FIX =====\n```\n\n## CRITICAL Rules - READ CAREFULLY\n\n1. **MINIMAL CHANGES ONLY** - Change ONLY what is necessary to fix the specific error. Nothing more.\n\n2. **PRESERVE EVERYTHING ELSE EXACTLY** - Every line that is NOT part of the fix must be returned EXACTLY as it appeared in the input, character-for-character, including:\n   - Comments and documentation\n   - Blank lines (including leading and trailing blank lines)\n   - All whitespace (including trailing newlines at the end of the snippet)\n   - Other variable declarations\n   - Function definitions\n   - String content (including multi-line strings)\n\n   **CRITICAL**: If the input snippet ends with blank lines or newlines, your output MUST end with the exact same number of blank lines/newlines. Do NOT trim trailing whitespace.\n\n3. **DO NOT under any circumstances**:\n   - Delete lines that aren't related to the fix\n   - Add code that isn't required for the fix\n   - \"Clean up\" or \"improve\" surrounding code\n   - Modify comments or documentation\n   - Change formatting on unrelated lines\n   - Remove blank lines\n   - Add blank lines (unless the fix specifically requires it)\n   - Modify string literals or docstrings\n   - Delete function definitions\n   - Remove dictionary entries or list items unrelated to the fix\n\n4. **Maintain RELATIVE indentation** - The snippet has had its base indentation removed. Preserve relative indentation exactly. If a line has 4 spaces in the input, it must have 4 spaces in your output.\n\n5. **One fix block per signal** - If multiple signals, provide multiple fix blocks\n\n6. **Use context for understanding only** - The context window, imports, and enclosing function help you understand the code, but you only return the fixed edit_snippet\n\n## Example - Correct Minimal Fix\n\nInput:\n- Error: \"Need type annotation for 'cache'\" on line 173\n- Edit Snippet (error on line 4 of 7, lines 170-176):\n```\n}\n\nDEPRIORITIZE_QUERIES = {}\ncache = {}\n\n# Model configuration\nEMBEDDING_MODEL = \"text-embedding-3-large\"\n```\n(Note: The snippet ends with a newline after the last line - this MUST be preserved)\n\nCORRECT Response (only `cache = {}` changed to `cache: dict = {}`):\n```\n===== FIX FOR: app/config/tier_queries.py =====\nCONFIDENCE: 0.95\nREASONING: Added dict type annotation to cache variable to satisfy mypy\n\n```FIXED_CODE\n}\n\nDEPRIORITIZE_QUERIES = {}\ncache: dict = {}\n\n# Model configuration\nEMBEDDING_MODEL = \"text-embedding-3-large\"\n```\n\nWARNINGS: None\n===== END FIX =====\n```\n(Note: The output preserves the exact same trailing newline as the input)\n\n## Example - Preserving Trailing Whitespace\n\nInput snippet ending with blank lines (note the TWO newlines after the return statement):\n```\ndef get_clerk_settings() -> ClerkSettings:\n    # Load Clerk token validation settings from config helpers\n    return ClerkSettings.from_config()\n\n\n```\n\nCORRECT - Preserves both trailing newlines:\n```FIXED_CODE\ndef get_clerk_settings() -> ClerkSettings:\n    # Load Clerk token validation settings from config helpers\n    return ClerkSettings.from_config()\n\n\n```\n(Output MUST have the same TWO trailing newlines)\n\nWRONG - Trimming trailing newlines:\n```FIXED_CODE\ndef get_clerk_settings() -> ClerkSettings:\n    # Load Clerk token validation settings from config helpers\n    return ClerkSettings.from_config()\n```\n^ This is WRONG because it removed trailing newlines. The snippet MUST end with the same whitespace as the input.\n\n## Example - WRONG (Deleting Unrelated Content)\n\nIf the input snippet contains documentation or other code, you MUST preserve it:\n\nWRONG - Deleting unrelated lines:\n```FIXED_CODE\ncache: dict = {}\nEMBEDDING_MODEL = \"text-embedding-3-large\"\n```\n^ This is WRONG because it deleted the closing brace, blank lines, DEPRIORITIZE_QUERIES, and the comment.\n\n## Confidence Guidelines\n- High (>0.8): Simple fixes like type annotations, obvious corrections\n- Medium (0.5-0.8): Logic changes, type guards, refactoring\n- Low (<0.5): Complex changes, unclear intent - add detailed warnings\n\n\n\n## Ruff Lint Error Fixing - Specialized Guidance\n\nYou are fixing LINTING errors from Ruff. These are code quality, style, and\nbest practice issues - NOT security or type correctness.\n\nRisk Level: LOW to MEDIUM\nThese fixes should improve code quality without changing behavior.\n\nCommon Ruff Rule Categories:\n\nF (Pyflakes):\n- Unused imports/variables\n- Undefined names\n- Duplicate arguments\n- Invalid format strings\n\nE/W (pycodestyle):\n- Line length (E501)\n- Whitespace issues (E203, W291)\n- Indentation (E111, E114)\n- Blank lines (E302, E303)\n\nC (McCabe):\n- Complexity warnings (C901)\n- Too many branches/statements\n\nN (pep8-naming):\n- Naming conventions (N801-N818)\n- Lowercase function names\n- CamelCase class names\n\nI (isort):\n- Import sorting/organization\n\nUP (pyupgrade):\n- Outdated syntax\n- Type hint modernization\n\nFixing Strategies:\n\n1. **Remove Unused Code** - But verify it's truly unused\n   \u2705 Remove unused imports\n   \u2705 Remove unused variables\n   \u26a0\ufe0f Check for side effects first!\n\n2. **Simplify Logic** - Follow Python idioms\n   \u2705 `if x == True:` \u2192 `if x:`\n   \u2705 `if len(list) > 0:` \u2192 `if list:`\n   \u2705 Use comprehensions instead of loops\n\n3. **Fix Naming** - Follow PEP 8\n   \u2705 `MyFunction` \u2192 `my_function`\n   \u2705 `my_class` \u2192 `MyClass`\n\n4. **Modernize Syntax** - Use newer Python features\n   \u2705 `Union[str, int]` \u2192 `str | int` (Python 3.10+)\n   \u2705 `Optional[str]` \u2192 `str | None` (Python 3.10+)\n\n5. **Organize Imports** - Sort and group properly\n   \u2705 Standard library first\n   \u2705 Third-party second\n   \u2705 Local imports last\n\nNEVER do these:\n\u274c Remove code that has side effects (initializers, registrations)\n\u274c Change behavior to fix style\n\u274c Break working code to satisfy complexity metrics\n\u274c Remove \"unused\" variables that are part of unpacking\n\nSpecial Cases:\n\nComplexity Warnings (C901):\n- Don't just suppress with # noqa\n- Consider refactoring if genuinely complex\n- But set confidence < 0.7 for refactoring suggestions\n\nUnused Variables:\n- `x, y, z = tuple` - y might be \"unused\" but needed for unpacking\n- Consider renaming to `_` if truly unused: `x, _, z = tuple`\n\nLine Length (E501):\n- Can often be fixed by breaking long lines\n- But some URLs or strings are legitimately long\n- Use # noqa: E501 with comment explaining why\n\nConfidence Guidelines:\n- High (>0.8): Remove unused imports, fix obvious naming\n- Medium (0.5-0.8): Simplify logic, organize imports\n- Low (<0.5): Refactoring suggestions, complex changes\n\nRemember: Preserve behavior. These are style improvements, not bug fixes.\n",
    "user_prompt": "Tool: ruff\nSignal Type: lint\nNumber of Signals: 4\n\n============================================================\nSIGNAL 1\n============================================================\n\n## Error Information\n- File: ria/services/search_service.py\n- Message: f-string without any placeholders\n- Rule Code: F541\n- Severity: low\n- Location: Line 52, Column 21\n\n## Edit Snippet (FIX AND RETURN THIS)\nLines 50-54 (error on line 3 of 5)\n```python\n    logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n    logger.info(f\"Available columns: {len(df.columns)} total\")\n    logger.info(f\"Missing columns will be handled gracefully in filters\")\nelse:\n    logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n```\n\n## Context Window (for understanding, DO NOT return)\nLines 22-82\n```python\n\nlogger = get_logger(__name__)\n\n\ndef canonicalize_domain(value: Optional[str]) -> Optional[str]:\n    \"\"\"Canonicalize a domain value by extracting the netloc.\"\"\"\n    if not value:\n        return None\n    v = value.strip().lower()\n    if not v:\n        return None\n    if not v.startswith(\"http\"):\n        v_for_parse = \"http://\" + v\n    else:\n        v_for_parse = v\n    try:\n        netloc = urlparse(v_for_parse).netloc\n        if netloc.startswith(\"www.\"):\n            netloc = netloc[4:]\n        return netloc\n    except Exception:\n        return v\n\n\ndef ensure_columns(df: pl.DataFrame, required: List[str]) -> None:\n    \"\"\"Check for required columns and log warnings for missing ones instead of raising errors.\"\"\"\n    missing = [col for col in required if col not in df.columns]\n    if missing:\n        logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n        logger.info(f\"Available columns: {len(df.columns)} total\")\n        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n\ndef attach_domain_column(df: pl.DataFrame, column: str) -> pl.DataFrame:\n    \"\"\"Attach domain column if available, otherwise add empty domain column.\"\"\"\n    if column not in df.columns:\n        logger.warning(f\"\u26a0\ufe0f Website column '{column}' not found, adding empty domain column\")\n        return df.with_columns(pl.lit(None).alias(\"__domain\"))\n    \n    return df.with_columns(\n        pl.col(column)\n        .map_elements(canonicalize_domain, return_dtype=pl.Utf8)\n        .alias(\"__domain\")\n    )\n\n\ndef to_serializable_records(df: pl.DataFrame, limit: int) -> List[Dict[str, Any]]:\n    \"\"\"Convert DataFrame to list of dictionaries, limited to specified count.\"\"\"\n    if df.height == 0:\n        return []\n    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n\n```\n\n## Imports\n```python\n\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n\n```\n\n## Enclosing Function\nLines 44-56\n```python\n\n\ndef ensure_columns(df: pl.DataFrame, required: List[str]) -> None:\n    \"\"\"Check for required columns and log warnings for missing ones instead of raising errors.\"\"\"\n    missing = [col for col in required if col not in df.columns]\n    if missing:\n        logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n        logger.info(f\"Available columns: {len(df.columns)} total\")\n        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n\n\n```\n\n\n============================================================\nSIGNAL 2\n============================================================\n\n## Error Information\n- File: ria/services/search_service.py\n- Message: Loop control variable `field_name` not used within loop body\n- Rule Code: B007\n- Severity: low\n- Location: Line 82, Column 9\n\n## Edit Snippet (FIX AND RETURN THIS)\nLines 80-84 (error on line 3 of 5)\n```python\nfund_counts = []\n    \nfor field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n    if column_name in company_record and company_record[column_name] is not None:\n        try:\n\n```\n\n## Context Window (for understanding, DO NOT return)\nLines 52-112\n```python\n        logger.info(f\"Missing columns will be handled gracefully in filters\")\n    else:\n        logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n\n\ndef attach_domain_column(df: pl.DataFrame, column: str) -> pl.DataFrame:\n    \"\"\"Attach domain column if available, otherwise add empty domain column.\"\"\"\n    if column not in df.columns:\n        logger.warning(f\"\u26a0\ufe0f Website column '{column}' not found, adding empty domain column\")\n        return df.with_columns(pl.lit(None).alias(\"__domain\"))\n    \n    return df.with_columns(\n        pl.col(column)\n        .map_elements(canonicalize_domain, return_dtype=pl.Utf8)\n        .alias(\"__domain\")\n    )\n\n\ndef to_serializable_records(df: pl.DataFrame, limit: int) -> List[Dict[str, Any]]:\n    \"\"\"Convert DataFrame to list of dictionaries, limited to specified count.\"\"\"\n    if df.height == 0:\n        return []\n    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n\n```\n\n## Imports\n```python\n\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n\n```\n\n## Enclosing Function\nLines 76-99\n```python\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\n\n```\n\n\n============================================================\nSIGNALS 3-4 (shared edit region)\n============================================================\n\n## Error 1\n- File: ria/services/search_service.py\n- Message: Use `dict` instead of `Dict` for type annotation\n- Rule Code: UP006\n- Severity: low\n- Location: Line 100, Column 67\n\n## Error 2\n- File: ria/services/search_service.py\n- Message: Loop control variable `field_name` not used within loop body\n- Rule Code: B007\n- Severity: low\n- Location: Line 104, Column 9\n\n## Edit Snippet (FIX ALL ERRORS ABOVE AND RETURN THIS)\nLines 98-106 (2 errors in 9 lines)\n```python\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n\n```\n\n## Context Window (for understanding, DO NOT return)\nLines 70-130\n```python\ndef to_serializable_records(df: pl.DataFrame, limit: int) -> List[Dict[str, Any]]:\n    \"\"\"Convert DataFrame to list of dictionaries, limited to specified count.\"\"\"\n    if df.height == 0:\n        return []\n    take = min(limit, df.height)\n    return df.head(take).to_dicts()\n\n\ndef get_top_3_private_funds(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 private fund types by count for a company.\"\"\"\n    fund_counts = []\n    \n    for field_name, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    fund_counts.append({\n                        \"category\": display_name,\n                        \"count\": count\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by count (highest first) and return top 3\n    fund_counts.sort(key=lambda x: x[\"count\"], reverse=True)\n    return fund_counts[:3]\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by percentage (highest first) and return top 3\n    allocations.sort(key=lambda x: x[\"percentage\"], reverse=True)\n    return allocations[:3]\n\n\ndef get_total_clients(company_record: Dict[str, Any]) -> int:\n    \"\"\"Get total count of all clients for a company by summing all client type columns.\"\"\"\n    total_count = 0\n    \n    for column_name in ALL_CLIENT_TYPE_COLUMNS:\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                count = int(company_record[column_name])\n                if count > 0:\n\n```\n\n## Imports\n```python\n\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n\n```\n\n## Enclosing Function\nLines 98-121\n```python\n\n\ndef get_top_3_allocations(company_record: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n    allocations = []\n    \n    for field_name, column_name in SMA_ALLOCATION_COLUMNS.items():\n        if column_name in company_record and company_record[column_name] is not None:\n            try:\n                percentage = float(company_record[column_name])\n                if percentage > 0:\n                    display_name = DISPLAY_NAME_MAPPING.get(column_name, column_name)\n                    allocations.append({\n                        \"category\": display_name,\n                        \"percentage\": percentage\n                    })\n            except (ValueError, TypeError):\n                continue\n    \n    # Sort by percentage (highest first) and return top 3\n    allocations.sort(key=lambda x: x[\"percentage\"], reverse=True)\n    return allocations[:3]\n\n\n\n```\n\n\nPlease provide fixes for the above signals using the specified response format."
  },
  "llm_response": [
    "===== FIX FOR: ria/services/search_service.py =====\n",
    "CONFIDENCE: 0.95\n",
    "REASONING: Removed f-string prefix from string literal that has no placeholders\n",
    "\n",
    "```FIXED_CODE\n",
    "    logger.warning(f\"\u26a0\ufe0f Dataset missing {len(missing)} columns: {', '.join(missing)}\")\n",
    "    logger.info(f\"Available columns: {len(df.columns)} total\")\n",
    "    logger.info(\"Missing columns will be handled gracefully in filters\")\n",
    "else:\n",
    "    logger.info(f\"\u2705 All {len(required)} required columns found in dataset\")\n",
    "\n",
    "```\n",
    "\n",
    "WARNINGS: None\n",
    "===== END FIX =====\n",
    "\n",
    "===== FIX FOR: ria/services/search_service.py =====\n",
    "CONFIDENCE: 0.90\n",
    "REASONING: Renamed unused loop variable field_name to _ to indicate it's intentionally unused\n",
    "\n",
    "```FIXED_CODE\n",
    "fund_counts = []\n",
    "    \n",
    "for _, column_name in PRIVATE_FUND_COUNT_COLUMNS.items():\n",
    "    if column_name in company_record and company_record[column_name] is not None:\n",
    "        try:\n",
    "\n",
    "```\n",
    "\n",
    "WARNINGS: None\n",
    "===== END FIX =====\n",
    "\n",
    "===== FIX FOR: ria/services/search_service.py =====\n",
    "CONFIDENCE: 0.95\n",
    "REASONING: Updated Dict to dict for modern type annotation and renamed unused loop variable field_name to _\n",
    "\n",
    "```FIXED_CODE\n",
    "\n",
    "\n",
    "def get_top_3_allocations(company_record: dict[str, Any]) -> list[dict[str, Any]]:\n",
    "    \"\"\"Get top 3 SMA allocation categories by percentage for a company.\"\"\"\n",
    "    allocations = []\n",
    "    \n",
    "    for _, column_name in SMA_ALLOCATION_COLUMNS.items():\n",
    "        if column_name in company_record and company_record[column_name] is not None:\n",
    "            try:\n",
    "\n",
    "```\n",
    "\n",
    "WARNINGS: None\n",
    "===== END FIX ====="
  ]
}
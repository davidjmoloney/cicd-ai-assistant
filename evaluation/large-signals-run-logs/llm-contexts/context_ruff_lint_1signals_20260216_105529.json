{
  "_debug_metadata": {
    "timestamp": "20260216_105529",
    "tool_id": "ruff",
    "signal_type": "lint",
    "num_signals": 1,
    "signal_files": [
      "ria/services/search_service.py"
    ],
    "system_prompt_length": 8600,
    "user_prompt_length": 7400
  },
  "context": {
    "group": {
      "tool_id": "ruff",
      "signal_type": "lint",
      "group_size": 1
    },
    "signals": [
      {
        "signal": {
          "tool_id": "ruff",
          "signal_type": "lint",
          "severity": "low",
          "rule_code": "UP006",
          "message": "Use `list` instead of `List` for type annotation",
          "docs_url": "https://docs.astral.sh/ruff/rules/non-pep585-annotation",
          "file_path": "ria/services/search_service.py",
          "span": {
            "start": {
              "row": 191,
              "column": 84
            },
            "end": {
              "row": 191,
              "column": 88
            }
          }
        },
        "file_read_error": null,
        "code_context": {
          "window": {
            "file_path": "ria/services/search_service.py",
            "start_row": 161,
            "end_row": 221,
            "text": "    Intelligent company name search with best-in-class ensemble fuzzy matching.\n    \n    Strategy:\n    1. Try exact match first (case-insensitive)\n    2. If no exact match, use ensemble fuzzy matching\n    3. Return only high-quality matches (quality over quantity)\n    \n    Ensemble Algorithm:\n    - Uses 4 different similarity algorithms for robustness\n    - Weighted combination ensures balanced matching\n    - Quality threshold prevents weak matches\n    \"\"\"\n    search_name_lower = search_name.lower().strip()\n    \n    # Phase 1: Exact match (case-insensitive)\n    exact_matches = df.filter(\n        pl.col(NAME_COLUMN).str.to_lowercase() == search_name_lower\n    )\n    \n    if not exact_matches.is_empty():\n        logger.info(f\"Found {exact_matches.height} exact matches for '{search_name}'\")\n        return to_serializable_records(exact_matches, max_results)\n    \n    # Phase 2: Ensemble fuzzy matching\n    logger.info(f\"No exact matches found, performing fuzzy search for '{search_name}'\")\n    fuzzy_matches = ensemble_fuzzy_search(df, search_name, max_results)\n    \n    return fuzzy_matches\n\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n    \n    Ensemble Components:\n    1. Ratio (40%): Overall character similarity - handles typos\n    2. Partial Ratio (25%): Best substring match - handles partial names  \n    3. Token Sort Ratio (20%): Word order independent - handles \"Company American\" vs \"American Company\"\n    4. Token Set Ratio (15%): Word overlap - handles extra/missing words\n    \n    Why this ensemble is robust:\n    - Multiple algorithms catch different types of variations\n    - Weighted combination balances different matching strategies\n    - Quality threshold (0.6) ensures only meaningful matches\n    - Handles: typos, partial names, word order, extra words, missing words\n    \"\"\"\n    try:\n        from rapidfuzz import fuzz\n    except ImportError:\n        logger.warning(\"rapidfuzz not available, falling back to basic matching\")\n        return []\n    \n    search_name_lower = search_name.lower().strip()\n    \n    # Get all company data for comparison (preserve all columns for preview mapping)\n    company_data = df.to_dicts()\n    \n    scored_matches = []\n    \n    for company in company_data:\n        company_name = company[NAME_COLUMN]\n"
          },
          "imports": {
            "file_path": "ria/services/search_service.py",
            "start_row": 1,
            "end_row": 14,
            "text": "\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n"
          },
          "enclosing_function": {
            "file_path": "ria/services/search_service.py",
            "start_row": 189,
            "end_row": 270,
            "text": "\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n    \n    Ensemble Components:\n    1. Ratio (40%): Overall character similarity - handles typos\n    2. Partial Ratio (25%): Best substring match - handles partial names  \n    3. Token Sort Ratio (20%): Word order independent - handles \"Company American\" vs \"American Company\"\n    4. Token Set Ratio (15%): Word overlap - handles extra/missing words\n    \n    Why this ensemble is robust:\n    - Multiple algorithms catch different types of variations\n    - Weighted combination balances different matching strategies\n    - Quality threshold (0.6) ensures only meaningful matches\n    - Handles: typos, partial names, word order, extra words, missing words\n    \"\"\"\n    try:\n        from rapidfuzz import fuzz\n    except ImportError:\n        logger.warning(\"rapidfuzz not available, falling back to basic matching\")\n        return []\n    \n    search_name_lower = search_name.lower().strip()\n    \n    # Get all company data for comparison (preserve all columns for preview mapping)\n    company_data = df.to_dicts()\n    \n    scored_matches = []\n    \n    for company in company_data:\n        company_name = company[NAME_COLUMN]\n        if not company_name:\n            continue\n            \n        company_name_lower = company_name.lower().strip()\n        \n        # Calculate ensemble score using 4 different algorithms\n        scores = {\n            'ratio': fuzz.ratio(search_name_lower, company_name_lower) / 100.0,\n            'partial_ratio': fuzz.partial_ratio(search_name_lower, company_name_lower) / 100.0,\n            'token_sort_ratio': fuzz.token_sort_ratio(search_name_lower, company_name_lower) / 100.0,\n            'token_set_ratio': fuzz.token_set_ratio(search_name_lower, company_name_lower) / 100.0,\n        }\n        \n        # Weighted ensemble score (tuned for company names)\n        ensemble_score = (\n            scores['ratio'] * 0.40 +           # Overall similarity (handles typos)\n            scores['partial_ratio'] * 0.25 +   # Best substring (handles partial names)\n            scores['token_sort_ratio'] * 0.20 + # Word order independent\n            scores['token_set_ratio'] * 0.15   # Word overlap (handles extra/missing words)\n        )\n        \n        # Quality threshold: only include matches above 60% similarity\n        if ensemble_score >= 0.6:\n            company['match_score'] = round(ensemble_score, 3)\n            company['match_details'] = {\n                'ratio': round(scores['ratio'], 3),\n                'partial_ratio': round(scores['partial_ratio'], 3),\n                'token_sort_ratio': round(scores['token_sort_ratio'], 3),\n                'token_set_ratio': round(scores['token_set_ratio'], 3)\n            }\n            scored_matches.append(company)\n    \n    # Sort by ensemble score (highest first)\n    scored_matches.sort(key=lambda x: x['match_score'], reverse=True)\n    \n    # Quality over quantity: return only strong matches\n    # If we have 2 strong matches (0.9+) and 8 weak ones (0.6-0.7), return only the 2 strong ones\n    strong_matches = [m for m in scored_matches if m['match_score'] >= 0.8]\n    if len(strong_matches) >= 2:\n        logger.info(f\"Found {len(strong_matches)} strong matches (\u22650.8), returning only strong matches\")\n        return strong_matches[:max_results]\n    \n    # Otherwise, return top matches up to the limit\n    result_count = min(len(scored_matches), max_results)\n    logger.info(f\"Found {len(scored_matches)} total matches, returning top {result_count} (scores: {[m['match_score'] for m in scored_matches[:result_count]]})\")\n    \n    return scored_matches[:result_count]\n\n\n"
          },
          "try_except_block": null,
          "class_definition": null,
          "type_aliases": null,
          "related_function": null,
          "module_constants": null
        },
        "edit_snippet": {
          "file_path": "ria/services/search_service.py",
          "start_row": 189,
          "end_row": 193,
          "text": "\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n",
          "original_text": "\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n",
          "error_line": 191,
          "error_line_in_snippet": 3,
          "snippet_length": 5,
          "base_indent": ""
        },
        "edit_window_type": "lines",
        "fix_context": {
          "exists": true,
          "applicability": "safe",
          "tool_message": "Replace with `list`",
          "edits": [
            {
              "span": {
                "start": {
                  "row": 191,
                  "column": 84
                },
                "end": {
                  "row": 191,
                  "column": 88
                }
              },
              "content": "list"
            }
          ]
        }
      }
    ],
    "merged_snippet_groups": [],
    "standalone_signal_indices": [
      0
    ]
  },
  "prompts": {
    "system_prompt": "You are an expert code repair agent. Your task is to make MINIMAL, SURGICAL fixes to code errors.\n\n## CRITICAL PRINCIPLE: MINIMAL CHANGES ONLY\n\nYour job is to fix ONLY the specific error mentioned. You are NOT improving, refactoring, or cleaning up code.\n\n**THE GOLDEN RULE**: Every line in your output that is NOT directly part of the fix MUST be IDENTICAL to the input - same content, same whitespace, same everything.\n\n## How This Works\n\nFor each error signal, you will receive:\n\n1. **Error Information**: Type, message, severity, and rule code\n2. **Edit Snippet**: A small code snippet (~13 lines) containing the error\n   - This is what you need to FIX and RETURN\n   - The error location within the snippet is indicated (e.g., \"Error on line 4 of 13\")\n3. **Context Window**: A larger code window (~30 lines) around the error for understanding\n   - Use this to understand the surrounding code, but DON'T return it\n\n4. **Tailored Context** (varies by signal type - optimized to reduce token usage):\n   - **Imports**: The file's import block (for type definitions, dependencies)\n     - Included for: type errors, undefined names, most issues\n     - Excluded for: import-only errors, bare except blocks\n   - **Enclosing Function**: The function containing the error (for understanding scope/logic)\n     - Included for: type errors, docstring errors, function-level issues\n     - Excluded for: import errors (global scope), bare except (sent separately)\n   - **Try/Except Block**: The try/except block containing the error\n     - Included for: bare except errors (E722)\n     - Excluded for: most other errors\n\nNote: Context is carefully selected to provide what you need while minimizing token usage.\nNot all context is present for every error - you'll only receive relevant context.\n\n## Response Format\n\nFor EACH signal/snippet you receive, respond with this EXACT format:\n\n```\n===== FIX FOR: <file_path> =====\nCONFIDENCE: <0.0-1.0>\nREASONING: <brief explanation of the fix>\n\n```FIXED_CODE\n<complete fixed snippet - ALL lines from edit_snippet, with ONLY the fix applied>\n```\n\nWARNINGS: <any caveats, or \"None\">\n===== END FIX =====\n```\n\n## CRITICAL Rules - READ CAREFULLY\n\n1. **MINIMAL CHANGES ONLY** - Change ONLY what is necessary to fix the specific error. Nothing more.\n\n2. **PRESERVE EVERYTHING ELSE EXACTLY** - Every line that is NOT part of the fix must be returned EXACTLY as it appeared in the input, character-for-character, including:\n   - Comments and documentation\n   - Blank lines (including leading and trailing blank lines)\n   - All whitespace (including trailing newlines at the end of the snippet)\n   - Other variable declarations\n   - Function definitions\n   - String content (including multi-line strings)\n\n   **CRITICAL**: If the input snippet ends with blank lines or newlines, your output MUST end with the exact same number of blank lines/newlines. Do NOT trim trailing whitespace.\n\n3. **DO NOT under any circumstances**:\n   - Delete lines that aren't related to the fix\n   - Add code that isn't required for the fix\n   - \"Clean up\" or \"improve\" surrounding code\n   - Modify comments or documentation\n   - Change formatting on unrelated lines\n   - Remove blank lines\n   - Add blank lines (unless the fix specifically requires it)\n   - Modify string literals or docstrings\n   - Delete function definitions\n   - Remove dictionary entries or list items unrelated to the fix\n\n4. **Maintain RELATIVE indentation** - The snippet has had its base indentation removed. Preserve relative indentation exactly. If a line has 4 spaces in the input, it must have 4 spaces in your output.\n\n5. **One fix block per signal** - If multiple signals, provide multiple fix blocks\n\n6. **Use context for understanding only** - The context window, imports, and enclosing function help you understand the code, but you only return the fixed edit_snippet\n\n## Example - Correct Minimal Fix\n\nInput:\n- Error: \"Need type annotation for 'cache'\" on line 173\n- Edit Snippet (error on line 4 of 7, lines 170-176):\n```\n}\n\nDEPRIORITIZE_QUERIES = {}\ncache = {}\n\n# Model configuration\nEMBEDDING_MODEL = \"text-embedding-3-large\"\n```\n(Note: The snippet ends with a newline after the last line - this MUST be preserved)\n\nCORRECT Response (only `cache = {}` changed to `cache: dict = {}`):\n```\n===== FIX FOR: app/config/tier_queries.py =====\nCONFIDENCE: 0.95\nREASONING: Added dict type annotation to cache variable to satisfy mypy\n\n```FIXED_CODE\n}\n\nDEPRIORITIZE_QUERIES = {}\ncache: dict = {}\n\n# Model configuration\nEMBEDDING_MODEL = \"text-embedding-3-large\"\n```\n\nWARNINGS: None\n===== END FIX =====\n```\n(Note: The output preserves the exact same trailing newline as the input)\n\n## Example - Preserving Trailing Whitespace\n\nInput snippet ending with blank lines (note the TWO newlines after the return statement):\n```\ndef get_clerk_settings() -> ClerkSettings:\n    # Load Clerk token validation settings from config helpers\n    return ClerkSettings.from_config()\n\n\n```\n\nCORRECT - Preserves both trailing newlines:\n```FIXED_CODE\ndef get_clerk_settings() -> ClerkSettings:\n    # Load Clerk token validation settings from config helpers\n    return ClerkSettings.from_config()\n\n\n```\n(Output MUST have the same TWO trailing newlines)\n\nWRONG - Trimming trailing newlines:\n```FIXED_CODE\ndef get_clerk_settings() -> ClerkSettings:\n    # Load Clerk token validation settings from config helpers\n    return ClerkSettings.from_config()\n```\n^ This is WRONG because it removed trailing newlines. The snippet MUST end with the same whitespace as the input.\n\n## Example - WRONG (Deleting Unrelated Content)\n\nIf the input snippet contains documentation or other code, you MUST preserve it:\n\nWRONG - Deleting unrelated lines:\n```FIXED_CODE\ncache: dict = {}\nEMBEDDING_MODEL = \"text-embedding-3-large\"\n```\n^ This is WRONG because it deleted the closing brace, blank lines, DEPRIORITIZE_QUERIES, and the comment.\n\n## Confidence Guidelines\n- High (>0.8): Simple fixes like type annotations, obvious corrections\n- Medium (0.5-0.8): Logic changes, type guards, refactoring\n- Low (<0.5): Complex changes, unclear intent - add detailed warnings\n\n\n\n## Ruff Lint Error Fixing - Specialized Guidance\n\nYou are fixing LINTING errors from Ruff. These are code quality, style, and\nbest practice issues - NOT security or type correctness.\n\nRisk Level: LOW to MEDIUM\nThese fixes should improve code quality without changing behavior.\n\nCommon Ruff Rule Categories:\n\nF (Pyflakes):\n- Unused imports/variables\n- Undefined names\n- Duplicate arguments\n- Invalid format strings\n\nE/W (pycodestyle):\n- Line length (E501)\n- Whitespace issues (E203, W291)\n- Indentation (E111, E114)\n- Blank lines (E302, E303)\n\nC (McCabe):\n- Complexity warnings (C901)\n- Too many branches/statements\n\nN (pep8-naming):\n- Naming conventions (N801-N818)\n- Lowercase function names\n- CamelCase class names\n\nI (isort):\n- Import sorting/organization\n\nUP (pyupgrade):\n- Outdated syntax\n- Type hint modernization\n\nFixing Strategies:\n\n1. **Remove Unused Code** - But verify it's truly unused\n   \u2705 Remove unused imports\n   \u2705 Remove unused variables\n   \u26a0\ufe0f Check for side effects first!\n\n2. **Simplify Logic** - Follow Python idioms\n   \u2705 `if x == True:` \u2192 `if x:`\n   \u2705 `if len(list) > 0:` \u2192 `if list:`\n   \u2705 Use comprehensions instead of loops\n\n3. **Fix Naming** - Follow PEP 8\n   \u2705 `MyFunction` \u2192 `my_function`\n   \u2705 `my_class` \u2192 `MyClass`\n\n4. **Modernize Syntax** - Use newer Python features\n   \u2705 `Union[str, int]` \u2192 `str | int` (Python 3.10+)\n   \u2705 `Optional[str]` \u2192 `str | None` (Python 3.10+)\n\n5. **Organize Imports** - Sort and group properly\n   \u2705 Standard library first\n   \u2705 Third-party second\n   \u2705 Local imports last\n\nNEVER do these:\n\u274c Remove code that has side effects (initializers, registrations)\n\u274c Change behavior to fix style\n\u274c Break working code to satisfy complexity metrics\n\u274c Remove \"unused\" variables that are part of unpacking\n\nSpecial Cases:\n\nComplexity Warnings (C901):\n- Don't just suppress with # noqa\n- Consider refactoring if genuinely complex\n- But set confidence < 0.7 for refactoring suggestions\n\nUnused Variables:\n- `x, y, z = tuple` - y might be \"unused\" but needed for unpacking\n- Consider renaming to `_` if truly unused: `x, _, z = tuple`\n\nLine Length (E501):\n- Can often be fixed by breaking long lines\n- But some URLs or strings are legitimately long\n- Use # noqa: E501 with comment explaining why\n\nConfidence Guidelines:\n- High (>0.8): Remove unused imports, fix obvious naming\n- Medium (0.5-0.8): Simplify logic, organize imports\n- Low (<0.5): Refactoring suggestions, complex changes\n\nRemember: Preserve behavior. These are style improvements, not bug fixes.\n",
    "user_prompt": "Tool: ruff\nSignal Type: lint\nNumber of Signals: 1\n\n============================================================\nSIGNAL 1\n============================================================\n\n## Error Information\n- File: ria/services/search_service.py\n- Message: Use `list` instead of `List` for type annotation\n- Rule Code: UP006\n- Severity: low\n- Location: Line 191, Column 84\n\n## Edit Snippet (FIX AND RETURN THIS)\nLines 189-193 (error on line 3 of 5)\n```python\n\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n\n```\n\n## Context Window (for understanding, DO NOT return)\nLines 161-221\n```python\n    Intelligent company name search with best-in-class ensemble fuzzy matching.\n    \n    Strategy:\n    1. Try exact match first (case-insensitive)\n    2. If no exact match, use ensemble fuzzy matching\n    3. Return only high-quality matches (quality over quantity)\n    \n    Ensemble Algorithm:\n    - Uses 4 different similarity algorithms for robustness\n    - Weighted combination ensures balanced matching\n    - Quality threshold prevents weak matches\n    \"\"\"\n    search_name_lower = search_name.lower().strip()\n    \n    # Phase 1: Exact match (case-insensitive)\n    exact_matches = df.filter(\n        pl.col(NAME_COLUMN).str.to_lowercase() == search_name_lower\n    )\n    \n    if not exact_matches.is_empty():\n        logger.info(f\"Found {exact_matches.height} exact matches for '{search_name}'\")\n        return to_serializable_records(exact_matches, max_results)\n    \n    # Phase 2: Ensemble fuzzy matching\n    logger.info(f\"No exact matches found, performing fuzzy search for '{search_name}'\")\n    fuzzy_matches = ensemble_fuzzy_search(df, search_name, max_results)\n    \n    return fuzzy_matches\n\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n    \n    Ensemble Components:\n    1. Ratio (40%): Overall character similarity - handles typos\n    2. Partial Ratio (25%): Best substring match - handles partial names  \n    3. Token Sort Ratio (20%): Word order independent - handles \"Company American\" vs \"American Company\"\n    4. Token Set Ratio (15%): Word overlap - handles extra/missing words\n    \n    Why this ensemble is robust:\n    - Multiple algorithms catch different types of variations\n    - Weighted combination balances different matching strategies\n    - Quality threshold (0.6) ensures only meaningful matches\n    - Handles: typos, partial names, word order, extra words, missing words\n    \"\"\"\n    try:\n        from rapidfuzz import fuzz\n    except ImportError:\n        logger.warning(\"rapidfuzz not available, falling back to basic matching\")\n        return []\n    \n    search_name_lower = search_name.lower().strip()\n    \n    # Get all company data for comparison (preserve all columns for preview mapping)\n    company_data = df.to_dicts()\n    \n    scored_matches = []\n    \n    for company in company_data:\n        company_name = company[NAME_COLUMN]\n\n```\n\n## Imports\n```python\n\"\"\"\nSearch Service\n\nThis service handles all search and filtering operations for RIA data.\nIncludes intelligent fuzzy matching and comprehensive filtering logic.\n\"\"\"\n\nfrom typing import Dict, Any, List, Optional\nfrom urllib.parse import urlparse\n\nimport polars as pl\n\nfrom ria.services.index_cache_service import get_index_cache\nfrom ria.utils.constants import (\n\n```\n\n## Enclosing Function\nLines 189-270\n```python\n\n\ndef ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Best-in-class ensemble fuzzy matching using multiple algorithms.\n    \n    Ensemble Components:\n    1. Ratio (40%): Overall character similarity - handles typos\n    2. Partial Ratio (25%): Best substring match - handles partial names  \n    3. Token Sort Ratio (20%): Word order independent - handles \"Company American\" vs \"American Company\"\n    4. Token Set Ratio (15%): Word overlap - handles extra/missing words\n    \n    Why this ensemble is robust:\n    - Multiple algorithms catch different types of variations\n    - Weighted combination balances different matching strategies\n    - Quality threshold (0.6) ensures only meaningful matches\n    - Handles: typos, partial names, word order, extra words, missing words\n    \"\"\"\n    try:\n        from rapidfuzz import fuzz\n    except ImportError:\n        logger.warning(\"rapidfuzz not available, falling back to basic matching\")\n        return []\n    \n    search_name_lower = search_name.lower().strip()\n    \n    # Get all company data for comparison (preserve all columns for preview mapping)\n    company_data = df.to_dicts()\n    \n    scored_matches = []\n    \n    for company in company_data:\n        company_name = company[NAME_COLUMN]\n        if not company_name:\n            continue\n            \n        company_name_lower = company_name.lower().strip()\n        \n        # Calculate ensemble score using 4 different algorithms\n        scores = {\n            'ratio': fuzz.ratio(search_name_lower, company_name_lower) / 100.0,\n            'partial_ratio': fuzz.partial_ratio(search_name_lower, company_name_lower) / 100.0,\n            'token_sort_ratio': fuzz.token_sort_ratio(search_name_lower, company_name_lower) / 100.0,\n            'token_set_ratio': fuzz.token_set_ratio(search_name_lower, company_name_lower) / 100.0,\n        }\n        \n        # Weighted ensemble score (tuned for company names)\n        ensemble_score = (\n            scores['ratio'] * 0.40 +           # Overall similarity (handles typos)\n            scores['partial_ratio'] * 0.25 +   # Best substring (handles partial names)\n            scores['token_sort_ratio'] * 0.20 + # Word order independent\n            scores['token_set_ratio'] * 0.15   # Word overlap (handles extra/missing words)\n        )\n        \n        # Quality threshold: only include matches above 60% similarity\n        if ensemble_score >= 0.6:\n            company['match_score'] = round(ensemble_score, 3)\n            company['match_details'] = {\n                'ratio': round(scores['ratio'], 3),\n                'partial_ratio': round(scores['partial_ratio'], 3),\n                'token_sort_ratio': round(scores['token_sort_ratio'], 3),\n                'token_set_ratio': round(scores['token_set_ratio'], 3)\n            }\n            scored_matches.append(company)\n    \n    # Sort by ensemble score (highest first)\n    scored_matches.sort(key=lambda x: x['match_score'], reverse=True)\n    \n    # Quality over quantity: return only strong matches\n    # If we have 2 strong matches (0.9+) and 8 weak ones (0.6-0.7), return only the 2 strong ones\n    strong_matches = [m for m in scored_matches if m['match_score'] >= 0.8]\n    if len(strong_matches) >= 2:\n        logger.info(f\"Found {len(strong_matches)} strong matches (\u22650.8), returning only strong matches\")\n        return strong_matches[:max_results]\n    \n    # Otherwise, return top matches up to the limit\n    result_count = min(len(scored_matches), max_results)\n    logger.info(f\"Found {len(scored_matches)} total matches, returning top {result_count} (scores: {[m['match_score'] for m in scored_matches[:result_count]]})\")\n    \n    return scored_matches[:result_count]\n\n\n\n```\n\n\nPlease provide fixes for the above signals using the specified response format."
  },
  "llm_response": [
    "===== FIX FOR: ria/services/search_service.py =====\n",
    "CONFIDENCE: 0.95\n",
    "REASONING: Changed `List` to `list` in type annotation to use modern Python 3.9+ built-in generic type instead of typing module import\n",
    "\n",
    "```FIXED_CODE\n",
    "\n",
    "\n",
    "def ensemble_fuzzy_search(df: pl.DataFrame, search_name: str, max_results: int) -> list[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Best-in-class ensemble fuzzy matching using multiple algorithms.\n",
    "\n",
    "```\n",
    "\n",
    "WARNINGS: None\n",
    "===== END FIX ====="
  ]
}